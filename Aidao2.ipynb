{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZPsZrlIaGB2",
        "outputId": "27306a3f-a69b-4501-ea00-65940f23678f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'aidao24' already exists and is not an empty directory.\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.10/dist-packages (0.10.4)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.4)\n",
            "Requirement already satisfied: nibabel>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (24.1)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/atolstikov/aidao24\n",
        "!pip install nilearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "wuAiA4niaoBO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "JkbfD6ZAREfh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalDataset(Dataset):\n",
        "\n",
        "    def __init__(self,data,labels,transform):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        data = self.transform(self.data)\n",
        "        data = data.permute(1,0,2)\n",
        "        data = data[:,None,:,:]\n",
        "        return data[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "dVRAheGUjv7J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnu_csv = pd.read_csv(\"/content/aidao24/qualifiers_track_2/data/ts_cut/HCPex/bnu.csv\").iloc[:,0]\n",
        "bnu1 = np.load(\"/content/aidao24/qualifiers_track_2/data/ts_cut/HCPex/bnu1.npy\")\n",
        "bnu2 = np.load(\"/content/aidao24/qualifiers_track_2/data/ts_cut/HCPex/bnu2.npy\")\n",
        "ihb_csv = pd.read_csv(\"/content/aidao24/qualifiers_track_2/data/ts_cut/HCPex/ihb.csv\").iloc[:,0]\n",
        "ihb = np.load(\"/content/aidao24/qualifiers_track_2/data/ts_cut/HCPex/ihb.npy\")"
      ],
      "metadata": {
        "id": "dvciQr4Fat5i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnu = np.concatenate((bnu1,bnu2))"
      ],
      "metadata": {
        "id": "j8M5oBSdbZIe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "measure = ConnectivityMeasure(kind = 'correlation')\n",
        "bnu_cm = measure.fit_transform(bnu)\n",
        "ihb_cm = measure.fit_transform(ihb)"
      ],
      "metadata": {
        "id": "T9ptfAqNmlcE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.concatenate((bnu_cm,ihb_cm))\n",
        "labels = np.concatenate((bnu_csv,ihb_csv))"
      ],
      "metadata": {
        "id": "RWIMuff2m68z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "KMuAkVANoe4z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MedicalDataset(data,labels,transform)"
      ],
      "metadata": {
        "id": "htB-veIdn0tK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, 5, True)"
      ],
      "metadata": {
        "id": "ohkAdienoEr2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.forw = nn.Sequential(\n",
        "            #1x419x419\n",
        "            nn.Conv2d(1,8,30,5,0),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.SiLU(),\n",
        "            #8x78x78\n",
        "            nn.Conv2d(8,32,4,2,0),\n",
        "            nn.MaxPool2d(3,1,0),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.SiLU(),\n",
        "            #32x36x36\n",
        "            nn.Conv2d(32,128,5,2,0),\n",
        "            nn.MaxPool2d(2,1,0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.SiLU(),\n",
        "            #128x15x15\n",
        "            nn.Conv2d(128,512,4,2,0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.SiLU(),\n",
        "            #512x6x6\n",
        "            nn.Conv2d(512,512,6,2,0),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512,128),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(128,1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.forw(x)"
      ],
      "metadata": {
        "id": "1OqxoMy-qPVx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvClassifier().to(DEVICE)\n",
        "opt = optim.Adam(model.parameters(),lr = 3e-5)\n",
        "crit = nn.BCELoss()"
      ],
      "metadata": {
        "id": "o8_vHbCysRSk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    with tqdm(loader) as TQDM:\n",
        "        wrong = 0\n",
        "        for idx, (data,labels) in enumerate(TQDM):\n",
        "            if idx<30:\n",
        "                model.train()\n",
        "                data = data.to(DEVICE).type(torch.float32)\n",
        "                labels = labels.to(DEVICE).type(torch.float32)\n",
        "                predicted_labels = model(data).flatten()\n",
        "                loss = crit(predicted_labels, labels)\n",
        "\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "                TQDM.set_postfix({\"loss\":loss.item()})\n",
        "\n",
        "            else:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    data = data.to(DEVICE).type(torch.float32)\n",
        "                    labels = labels.to(DEVICE).type(torch.float32)\n",
        "                    predicted_labels = torch.round(model(data).flatten())\n",
        "                    wrong += torch.sum(torch.abs(predicted_labels - labels))\n",
        "        print(1 - wrong/12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec7IyEP1RScV",
        "outputId": "574fcc35-3df5-4ed7-aed3-7a3d4dd9b29f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:14<00:00,  2.26s/it, loss=0.381]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5000, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:14<00:00,  2.25s/it, loss=0.472]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9167, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:15<00:00,  2.30s/it, loss=0.0537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9167, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:14<00:00,  2.24s/it, loss=0.0106]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:15<00:00,  2.28s/it, loss=0.00573]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7B1xGjaA-tJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}